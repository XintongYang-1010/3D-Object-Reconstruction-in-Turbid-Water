GENERAL:
  GPU_ID: 0
  SEED: 2024
  WORKER: 1
  CHANNEL : 1 
  SAVE_PREFIX: 
  EXP_NAME: 
  CHECKPOINT_NAME: 'checkpoint'


DATA:
  DATA_TYPE: UHDM
  TEST_DATASET: 

  TRAIN_DATASET: 

  EPOCH_TIMES : 18

  TEST_NETS_DIR: checkpointminimum_kpt.pth

  pic_name : '15_101'

MODEL:
  EN_FEATURE_NUM: 48 # The initial channel number of dense blocks of encoder
  EN_INTER_NUM: 32 # The growth rate (intermediate channel number) of dense blocks of encoder
  DE_FEATURE_NUM: 64 # The initial channel number of dense blocks of decoder
  DE_INTER_NUM: 32 # The growth rate (intermediate channel number) of dense blocks of decoder
  SAM_NUMBER: 1 # The number of SAM for each encoder or decoder level; set 1 for our ESDNet, and 2 for ESDNet-L

TRAIN:
  BATCH_SIZE: 3
  LOADER:   crop # The loading way for training data, e.g., crop, resize, default; see ./dataset/load_data.py
  CROP_SIZE_X: 768 # Set the crop size if LOADER==crop
  CROP_SIZE_Y: 1536
  RESIZE_SIZE: 384 # Set the resizing size if LOADER==crop
  H: 1536
  W: 2016
  SAVE_ITER: 20 # Save training images/results at each SAVE_ITER*n iter
  LOAD_EPOCH: False # If specify it, loading the corresponding model for resuming training
  LAM: 1 # The loss weight for L1 loss
  LAM_P: 1 # The loss weight for perceptual loss

TEST:
  TEST_EPOCH: 201 # Input 'auto' for loading the latest model
  SAVE_IMG: True # The file type (e.g., jpg, png) for saving the output image; set False to avoid saving
  LOAD_PATH: True # If specify a load path for a checkpoint, TEST_EPOCH will be deprecated
  EVALUATION_METRIC: True # If True, calculate metrics
  EVALUATION_TIME: False # If True, calculate processing time per image; EVALUATION_METRIC will be deprecated for accurate statistics
  EVALUATION_COST: False #If True, calculate MACs and Parameters number

SOLVER:
  EPOCHS: 150 # The total training epochs
  T_0: 50 # The total epochs for the first learning cycle (learning rate warms up then)
  T_MULT: 1 # The learning cycle would be (T_0, T_0*T_MULT, T_0*T_MULT^2, T_0*T_MULT^3, ...)
  ETA_MIN: 0.000001 # Initial learning rate in each learning cycle
  BASE_LR: 0.0002 # Learning rate in the end of each learning cycle

